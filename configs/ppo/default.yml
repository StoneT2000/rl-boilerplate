# example config for scripts/train_ppo.py
seed: 0
env:
  env_id: PickCube-v1
  num_envs: 4096
  vectorization_method: "gpu"
  env_kwargs:
    sim_backend: "physx_cuda"
    control_mode: "pd_joint_delta_pos"
    reward_mode: "normalized_dense"

  
eval_num_envs:
  num_envs: 16
  env_kwargs:
    render_mode: "rgb_array"

train:
  total_timesteps: 10_000_000

ppo:
  gamma: 0.8
  gae_lambda: 0.9
  steps_per_env: 4
  update_epochs: 8
  num_minibatches: 32
  cudagraphs: true
  
network:
  actor:
    type: "mlp"
    arch_cfg:
      features: [64, 64]
      activation: "tanh"
      output_activation: "tanh"
  critic:
    type: "mlp"
    arch_cfg:
      features: [64, 64]
      activation: "tanh"
      output_activation: "tanh"

logger:
  project_name: "PPO"
  exp_name: "PickCube-v1"
  tensorboard: true
  wandb: true